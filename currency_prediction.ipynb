{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T13:56:06.831908Z","iopub.status.busy":"2024-05-14T13:56:06.831549Z","iopub.status.idle":"2024-05-14T13:56:11.579946Z","shell.execute_reply":"2024-05-14T13:56:11.578961Z","shell.execute_reply.started":"2024-05-14T13:56:06.831879Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ok\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import torch\n","\n","data=pd.read_csv('/kaggle/input/merged/merged_data.csv')\n","data.set_index('Date', inplace=True)\n","train_data, test_data = train_test_split(data, test_size=492, random_state=42)\n","print('ok')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_data "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T13:56:18.279511Z","iopub.status.busy":"2024-05-14T13:56:18.278651Z","iopub.status.idle":"2024-05-14T13:56:18.320580Z","shell.execute_reply":"2024-05-14T13:56:18.319533Z","shell.execute_reply.started":"2024-05-14T13:56:18.279460Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["**GPT2 Models**"]},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-14T13:56:26.207097Z","iopub.status.busy":"2024-05-14T13:56:26.206733Z","iopub.status.idle":"2024-05-14T13:56:46.835194Z","shell.execute_reply":"2024-05-14T13:56:46.834116Z","shell.execute_reply.started":"2024-05-14T13:56:26.207070Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"088d67dfe94f49198d332f28f7a4eca5","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29551ff622b545ff97bc69381e31ef59","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e3d1e8ff26c47f4adc2a826039bfc36","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca436d89975b4b69a0ad773d2fbd1177","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a36fa203dc9942e68abd2907bd7b5c52","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["ok\n"]}],"source":["\n","from transformers import GPT2Tokenizer\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","def prepare_data(data, tokenizer, max_seq_length):\n","    tokenized = tokenizer(\n","        list(data['clean text']), padding=True, truncation=True, max_length=max_seq_length, return_tensors=\"pt\"\n","        )\n","    labels = torch.tensor(\n","        data['increase_classes'].values,\n","        dtype=torch.int64\n","        )\n","    return TensorDataset(tokenized['input_ids'], tokenized['attention_mask'], labels)\n","\n","\n","max_seq_length = 128\n","\n","# Подготовка данных\n","train_dataset = prepare_data(train_data, tokenizer, max_seq_length)\n","test_dataset = prepare_data(test_data, tokenizer, max_seq_length)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n","print('ok')"]},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-05-14T13:57:28.555440Z","iopub.status.busy":"2024-05-14T13:57:28.555085Z","iopub.status.idle":"2024-05-14T13:57:32.622112Z","shell.execute_reply":"2024-05-14T13:57:32.621068Z","shell.execute_reply.started":"2024-05-14T13:57:28.555414Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cfc8ecb1d869493e820502771a58dd64","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import GPT2Model\n","import torch.nn as nn\n","\n","\n","# Определение модели\n","class GPT2Small(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.gpt = GPT2Model.from_pretrained('gpt2')\n","        self.classifier = nn.Sequential(\n","            nn.Linear(self.gpt.config.n_embd,64),\n","            nn.ReLU(),\n","            nn.Linear(64,3),\n","            nn.Softmax(dim=1)\n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        gpt_output = self.gpt(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = gpt_output.last_hidden_state[:, 0]\n","        predictions = self.classifier(pooled_output)\n","        return predictions\n","model=GPT2Small().to(device)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T14:08:25.648721Z","iopub.status.busy":"2024-05-14T14:08:25.647840Z","iopub.status.idle":"2024-05-14T14:08:26.303168Z","shell.execute_reply":"2024-05-14T14:08:26.302119Z","shell.execute_reply.started":"2024-05-14T14:08:25.648690Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ok\n"]}],"source":["from transformers import GPT2Model\n","import torch.nn as nn\n","\n","\n","# Определение модели\n","class GPT2Medium(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.gpt = GPT2Model.from_pretrained('gpt2')\n","        self.fc1 = nn.Linear(self.gpt.config.n_embd,256)\n","        self.act1 = nn.LeakyReLU()\n","        self.fc2 = nn.Linear(256,128)\n","        self.act2 = nn.ReLU()\n","        self.fc3 = nn.Linear(128,3)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, input_ids, attention_mask):\n","        gpt_output = self.gpt(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = gpt_output.last_hidden_state[:, 0]\n","        x = self.fc1(pooled_output)\n","        x = self.act1(x)\n","        x = self.fc2(x)\n","        x = self.act2(x)\n","        x = self.fc3(x)\n","        predictions = self.softmax(x)\n","        return predictions\n","model=GPT2Medium().to(device)\n","\n","print('ok')"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T14:26:51.753497Z","iopub.status.busy":"2024-05-14T14:26:51.752726Z","iopub.status.idle":"2024-05-14T14:26:52.385312Z","shell.execute_reply":"2024-05-14T14:26:52.384347Z","shell.execute_reply.started":"2024-05-14T14:26:51.753459Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ok\n"]}],"source":["from transformers import GPT2Model\n","import torch.nn as nn\n","\n","\n","# Определение модели\n","class GPT2Big(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.gpt = GPT2Model.from_pretrained('gpt2')\n","        self.fc1 = nn.Linear(self.gpt.config.n_embd,512)\n","        self.act1 = nn.ReLU()\n","        self.drop1 = nn.Dropout(0.5)\n","        self.fc2 = nn.Linear(512,256)\n","        self.act2 = nn.ReLU()\n","        self.drop2 = nn.Dropout(0.4)\n","        self.fc3 = nn.Linear(256,128)\n","        self.act3 = nn.ReLU()\n","        self.fc4 = nn.Linear(128,3)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, input_ids, attention_mask):\n","        gpt_output = self.gpt(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = gpt_output.last_hidden_state[:, 0]\n","        x = self.fc1(pooled_output)\n","        x = self.act1(x)\n","        x = self.drop1(x)\n","        x = self.fc2(x)\n","        x = self.act2(x)\n","        x = self.drop2(x)\n","        x = self.fc3(x)\n","        x = self.act3(x)\n","        x = self.fc4(x)\n","        predictions = self.softmax(x)\n","        return predictions\n","model=GPT2Big().to(device)\n","\n","print('ok')"]},{"cell_type":"markdown","metadata":{},"source":["**RoBERTa Models**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","from transformers import RobertaTokenizer\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","\n","def prepare_data(data, tokenizer, max_seq_length):\n","    tokenized = tokenizer(\n","        list(data['clean text']), padding=True, truncation=True, max_length=max_seq_length, return_tensors=\"pt\"\n","        )\n","    labels = torch.tensor(\n","        data['increase_classes'].values,\n","        dtype=torch.int64\n","        )\n","    return TensorDataset(tokenized['input_ids'], tokenized['attention_mask'], labels)\n","\n","\n","max_seq_length = 128\n","\n","# Подготовка данных\n","train_dataset = prepare_data(train_data, tokenizer, max_seq_length)\n","test_dataset = prepare_data(test_data, tokenizer, max_seq_length)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n","print('ok')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import RobertaModel\n","import torch.nn as nn\n","\n","\n","# Определение модели\n","class RobertaSmall(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.roberta = RobertaModel.from_pretrained('roberta-base')\n","        self.classifier = nn.Sequential(\n","            nn.Linear(self.roberta.config.hidden_size,64),\n","            nn.Linear(64, 3),\n","            nn.Softmax(dim=1)\n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = output.pooler_output\n","        predictions = self.classifier(pooled_output)\n","        return predictions\n","model=RobertaSmall().to(device)\n","\n","print('ok')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import RobertaModel\n","import torch.nn as nn\n","\n","\n","# Определение модели\n","class RobertaBig(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.roberta = RobertaModel.from_pretrained('roberta-base')\n","        self.fc1 = nn.Linear(self.roberta.config.hidden_size,512)\n","        self.bn1 = nn.BatchNorm1d(512)\n","        self.fc2 = nn.Linear(512,256)\n","        self.bn2 = nn.BatchNorm1d(256)\n","        self.fc3 = nn.Linear(256,90)\n","        self.fc4 = nn.Linear(90,3)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = output.pooler_output\n","        x = self.fc1(pooled_output)\n","        x = self.bn1(x)\n","        x = self.fc2(x)\n","        x = self.bn2(x)\n","        x = self.fc3(x)\n","        x = self.fc4(x)\n","        predictions = self.softmax(x)\n","        return predictions\n","model=RobertaBig().to(device)\n","\n","print('ok')"]},{"cell_type":"markdown","metadata":{},"source":["**BERT Models**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","from transformers import BertTokenizer\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","def prepare_data(data, tokenizer, max_seq_length):\n","    tokenized = tokenizer(\n","        list(data['clean text']), padding=True, truncation=True, max_length=max_seq_length, return_tensors=\"pt\"\n","        )\n","    labels = torch.tensor(\n","        data['increase_classes'].values,\n","        dtype=torch.int64\n","        )\n","    return TensorDataset(tokenized['input_ids'], tokenized['attention_mask'], labels)\n","\n","\n","max_seq_length = 128\n","\n","# Подготовка данных\n","train_dataset = prepare_data(train_data, tokenizer, max_seq_length)\n","test_dataset = prepare_data(test_data, tokenizer, max_seq_length)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n","print('ok')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import BertModel\n","import torch.nn as nn\n","\n","\n","# Определение модели\n","class BERTSmall(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        self.classifier = nn.Sequential(\n","            nn.Linear(self.bert.config.hidden_size,64),\n","            nn.Linear(64, 3),\n","            nn.Softmax(dim=1)\n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = output.pooler_output\n","        predictions = self.classifier(pooled_output)\n","        return predictions\n","model=BERTSmall().to(device)\n","\n","print('ok')"]},{"cell_type":"markdown","metadata":{},"source":["**Organizing for traininig**"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T14:27:02.342709Z","iopub.status.busy":"2024-05-14T14:27:02.342017Z","iopub.status.idle":"2024-05-14T14:27:02.353103Z","shell.execute_reply":"2024-05-14T14:27:02.352113Z","shell.execute_reply.started":"2024-05-14T14:27:02.342676Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ok\n"]}],"source":["def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    for batch, X in enumerate(dataloader):\n","        input_ids, attention_mask, labels = [x.to(device) for x in X]\n","        pred=model(input_ids,attention_mask)\n","        loss=loss_fn(pred,labels)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if batch % 10 == 0:\n","            loss, current = loss.item(), batch * len(input_ids)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","def test_loop(dataloader,model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    test_loss, correct = 0, 0\n","    \n","    with torch.no_grad():\n","        for batch in dataloader:\n","            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n","            pred = model(input_ids,attention_mask)\n","            test_loss+=loss_fn(pred, labels).item()\n","            correct += (pred.argmax(1) == labels).type(torch.float).sum().item()\n","    \n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n","    return test_loss, correct\n","\n","print('ok')"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T14:27:04.262744Z","iopub.status.busy":"2024-05-14T14:27:04.262039Z","iopub.status.idle":"2024-05-14T14:27:04.268990Z","shell.execute_reply":"2024-05-14T14:27:04.268205Z","shell.execute_reply.started":"2024-05-14T14:27:04.262710Z"},"trusted":true},"outputs":[],"source":["input_ids, attetion_mask, labels = next(iter(train_loader))\n","input_ids=input_ids.to(device)\n","attetion_mask=attetion_mask.to(device)\n","labels=labels.to(device)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T14:27:06.480492Z","iopub.status.busy":"2024-05-14T14:27:06.479664Z","iopub.status.idle":"2024-05-14T14:27:06.745588Z","shell.execute_reply":"2024-05-14T14:27:06.744655Z","shell.execute_reply.started":"2024-05-14T14:27:06.480458Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0.3861, 0.3697, 0.2441],\n","        [0.3357, 0.3251, 0.3392],\n","        [0.2991, 0.3815, 0.3194],\n","        [0.3526, 0.3576, 0.2899],\n","        [0.3285, 0.3578, 0.3137],\n","        [0.3080, 0.4166, 0.2754],\n","        [0.3010, 0.4010, 0.2980],\n","        [0.2787, 0.3928, 0.3285],\n","        [0.3324, 0.3994, 0.2682],\n","        [0.2737, 0.3909, 0.3354],\n","        [0.4036, 0.3178, 0.2786],\n","        [0.3397, 0.3711, 0.2892],\n","        [0.2707, 0.3524, 0.3769],\n","        [0.3339, 0.3740, 0.2921],\n","        [0.3556, 0.3512, 0.2933],\n","        [0.2884, 0.4418, 0.2699],\n","        [0.3007, 0.3725, 0.3268],\n","        [0.3002, 0.4047, 0.2952],\n","        [0.3364, 0.3219, 0.3417],\n","        [0.3569, 0.3583, 0.2849],\n","        [0.3387, 0.3156, 0.3457],\n","        [0.3212, 0.3598, 0.3190],\n","        [0.3627, 0.3383, 0.2989],\n","        [0.3662, 0.3311, 0.3027],\n","        [0.3944, 0.3674, 0.2382],\n","        [0.2394, 0.4590, 0.3016],\n","        [0.3072, 0.3507, 0.3421],\n","        [0.3346, 0.3599, 0.3054],\n","        [0.3344, 0.3854, 0.2802],\n","        [0.4123, 0.2992, 0.2884],\n","        [0.3268, 0.3631, 0.3100],\n","        [0.3700, 0.3726, 0.2574]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n","tensor([0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 0, 1, 1, 1, 2, 1, 2, 1, 0, 0,\n","        0, 1, 1, 1, 1, 0, 1, 1], device='cuda:0')\n"]}],"source":["pred=model(input_ids, attetion_mask)\n","print(pred)\n","res=pred.argmax(1)\n","print(res)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T14:27:13.050419Z","iopub.status.busy":"2024-05-14T14:27:13.049699Z","iopub.status.idle":"2024-05-14T14:27:13.057558Z","shell.execute_reply":"2024-05-14T14:27:13.056456Z","shell.execute_reply.started":"2024-05-14T14:27:13.050385Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["ok\n"]}],"source":["learning_rate = 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","lambda1 = lambda epoch: 0.90 ** epoch\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n","loss_fn = nn.CrossEntropyLoss()\n","print('ok')\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T14:27:14.461498Z","iopub.status.busy":"2024-05-14T14:27:14.461111Z","iopub.status.idle":"2024-05-14T14:27:14.466013Z","shell.execute_reply":"2024-05-14T14:27:14.464988Z","shell.execute_reply.started":"2024-05-14T14:27:14.461469Z"},"trusted":true},"outputs":[],"source":["test_l = []\n","accuracy = []"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T14:27:19.017048Z","iopub.status.busy":"2024-05-14T14:27:19.016194Z","iopub.status.idle":"2024-05-14T14:35:57.431258Z","shell.execute_reply":"2024-05-14T14:35:57.430271Z","shell.execute_reply.started":"2024-05-14T14:27:19.017018Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n","-------------------------------\n","loss: 1.136303  [    0/ 1472]\n","loss: 1.091820  [  320/ 1472]\n","loss: 1.009764  [  640/ 1472]\n","loss: 0.963723  [  960/ 1472]\n","loss: 1.018344  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 50.8%, Avg loss: 0.964905 \n","\n","Epoch 2\n","-------------------------------\n","loss: 0.952297  [    0/ 1472]\n","loss: 0.992125  [  320/ 1472]\n","loss: 0.968071  [  640/ 1472]\n","loss: 0.974693  [  960/ 1472]\n","loss: 0.966627  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 50.8%, Avg loss: 0.963104 \n","\n","Epoch 3\n","-------------------------------\n","loss: 0.955575  [    0/ 1472]\n","loss: 0.965947  [  320/ 1472]\n","loss: 0.954455  [  640/ 1472]\n","loss: 0.954709  [  960/ 1472]\n","loss: 0.976778  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 48.4%, Avg loss: 0.964676 \n","\n","Epoch 4\n","-------------------------------\n","loss: 0.974004  [    0/ 1472]\n","loss: 0.981209  [  320/ 1472]\n","loss: 0.953664  [  640/ 1472]\n","loss: 0.970518  [  960/ 1472]\n","loss: 0.949536  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 50.8%, Avg loss: 0.963802 \n","\n","Epoch 5\n","-------------------------------\n","loss: 0.969912  [    0/ 1472]\n","loss: 0.949652  [  320/ 1472]\n","loss: 0.961016  [  640/ 1472]\n","loss: 0.974487  [  960/ 1472]\n","loss: 0.965868  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 50.8%, Avg loss: 0.962047 \n","\n","Epoch 6\n","-------------------------------\n","loss: 0.954308  [    0/ 1472]\n","loss: 0.959640  [  320/ 1472]\n","loss: 0.958316  [  640/ 1472]\n","loss: 0.973073  [  960/ 1472]\n","loss: 1.025440  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 50.8%, Avg loss: 0.966623 \n","\n","Epoch 7\n","-------------------------------\n","loss: 0.970549  [    0/ 1472]\n","loss: 0.908225  [  320/ 1472]\n","loss: 0.902416  [  640/ 1472]\n","loss: 0.867287  [  960/ 1472]\n","loss: 0.833730  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 51.0%, Avg loss: 1.018547 \n","\n","Epoch 8\n","-------------------------------\n","loss: 0.916173  [    0/ 1472]\n","loss: 0.941376  [  320/ 1472]\n","loss: 0.846564  [  640/ 1472]\n","loss: 0.862373  [  960/ 1472]\n","loss: 0.816200  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 50.2%, Avg loss: 1.015993 \n","\n","Epoch 9\n","-------------------------------\n","loss: 0.866474  [    0/ 1472]\n","loss: 0.863517  [  320/ 1472]\n","loss: 0.780311  [  640/ 1472]\n","loss: 0.883320  [  960/ 1472]\n","loss: 0.793803  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 51.2%, Avg loss: 1.013963 \n","\n","Epoch 10\n","-------------------------------\n","loss: 0.864903  [    0/ 1472]\n","loss: 0.848020  [  320/ 1472]\n","loss: 0.847711  [  640/ 1472]\n","loss: 0.785656  [  960/ 1472]\n","loss: 0.853312  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 51.8%, Avg loss: 1.003415 \n","\n","Epoch 11\n","-------------------------------\n","loss: 0.780044  [    0/ 1472]\n","loss: 0.747968  [  320/ 1472]\n","loss: 0.815669  [  640/ 1472]\n","loss: 0.870697  [  960/ 1472]\n","loss: 0.899905  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 51.0%, Avg loss: 1.005675 \n","\n","Epoch 12\n","-------------------------------\n","loss: 0.845083  [    0/ 1472]\n","loss: 0.790763  [  320/ 1472]\n","loss: 0.722750  [  640/ 1472]\n","loss: 0.839407  [  960/ 1472]\n","loss: 0.930603  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 51.6%, Avg loss: 1.013800 \n","\n","Epoch 13\n","-------------------------------\n","loss: 0.886647  [    0/ 1472]\n","loss: 0.819976  [  320/ 1472]\n","loss: 0.903535  [  640/ 1472]\n","loss: 0.803165  [  960/ 1472]\n","loss: 0.853689  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 53.0%, Avg loss: 1.002828 \n","\n","Epoch 14\n","-------------------------------\n","loss: 0.827675  [    0/ 1472]\n","loss: 0.783930  [  320/ 1472]\n","loss: 0.799878  [  640/ 1472]\n","loss: 0.840713  [  960/ 1472]\n","loss: 0.952381  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 48.4%, Avg loss: 1.026822 \n","\n","Epoch 15\n","-------------------------------\n","loss: 0.802205  [    0/ 1472]\n","loss: 0.963043  [  320/ 1472]\n","loss: 0.772233  [  640/ 1472]\n","loss: 0.755036  [  960/ 1472]\n","loss: 0.934377  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 50.0%, Avg loss: 1.005906 \n","\n","Epoch 16\n","-------------------------------\n","loss: 0.836272  [    0/ 1472]\n","loss: 0.798726  [  320/ 1472]\n","loss: 0.863739  [  640/ 1472]\n","loss: 0.806307  [  960/ 1472]\n","loss: 0.711086  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 49.8%, Avg loss: 1.016206 \n","\n","Epoch 17\n","-------------------------------\n","loss: 0.875314  [    0/ 1472]\n","loss: 0.829077  [  320/ 1472]\n","loss: 0.892887  [  640/ 1472]\n","loss: 0.853939  [  960/ 1472]\n","loss: 0.884574  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 48.4%, Avg loss: 1.022114 \n","\n","Epoch 18\n","-------------------------------\n","loss: 0.920020  [    0/ 1472]\n","loss: 0.754538  [  320/ 1472]\n","loss: 0.906543  [  640/ 1472]\n","loss: 0.787108  [  960/ 1472]\n","loss: 0.814799  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 48.6%, Avg loss: 1.022611 \n","\n","Epoch 19\n","-------------------------------\n","loss: 0.864851  [    0/ 1472]\n","loss: 0.835763  [  320/ 1472]\n","loss: 0.815868  [  640/ 1472]\n","loss: 0.815390  [  960/ 1472]\n","loss: 0.795829  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 49.2%, Avg loss: 1.008701 \n","\n","Epoch 20\n","-------------------------------\n","loss: 0.795712  [    0/ 1472]\n","loss: 0.807116  [  320/ 1472]\n","loss: 0.889979  [  640/ 1472]\n","loss: 0.882219  [  960/ 1472]\n","loss: 0.729880  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 47.8%, Avg loss: 1.015347 \n","\n","Epoch 21\n","-------------------------------\n","loss: 0.880199  [    0/ 1472]\n","loss: 0.868112  [  320/ 1472]\n","loss: 0.788319  [  640/ 1472]\n","loss: 0.886607  [  960/ 1472]\n","loss: 0.965530  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 48.0%, Avg loss: 1.022479 \n","\n","Epoch 22\n","-------------------------------\n","loss: 0.785669  [    0/ 1472]\n","loss: 0.861526  [  320/ 1472]\n","loss: 0.780965  [  640/ 1472]\n","loss: 0.825343  [  960/ 1472]\n","loss: 0.875526  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 48.2%, Avg loss: 1.025539 \n","\n","Epoch 23\n","-------------------------------\n","loss: 0.903993  [    0/ 1472]\n","loss: 0.899007  [  320/ 1472]\n","loss: 0.680866  [  640/ 1472]\n","loss: 0.790113  [  960/ 1472]\n","loss: 0.775758  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 47.8%, Avg loss: 1.029742 \n","\n","Epoch 24\n","-------------------------------\n","loss: 0.788753  [    0/ 1472]\n","loss: 0.869653  [  320/ 1472]\n","loss: 0.782094  [  640/ 1472]\n","loss: 0.941852  [  960/ 1472]\n","loss: 0.756223  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 49.2%, Avg loss: 1.015287 \n","\n","Epoch 25\n","-------------------------------\n","loss: 0.802350  [    0/ 1472]\n","loss: 0.664700  [  320/ 1472]\n","loss: 0.866689  [  640/ 1472]\n","loss: 0.759093  [  960/ 1472]\n","loss: 0.859188  [ 1280/ 1472]\n","Test Error: \n"," Accuracy: 48.6%, Avg loss: 1.018485 \n","\n","Done!\n"]}],"source":["\n","epochs = 25\n","for t in range(epochs):\n","      print(f\"Epoch {t+1}\\n-------------------------------\")\n","      model.train(True)\n","      train_loop(train_loader, model, loss_fn, optimizer)\n","      scheduler.step()\n","      model.train(False)\n","      t,a =test_loop(test_loader, model, loss_fn)\n","      test_l.append(t)\n","      accuracy.append(a)\n","print(\"Done!\")\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T14:37:00.704422Z","iopub.status.busy":"2024-05-14T14:37:00.703471Z","iopub.status.idle":"2024-05-14T14:37:00.712372Z","shell.execute_reply":"2024-05-14T14:37:00.711486Z","shell.execute_reply.started":"2024-05-14T14:37:00.704381Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","test_loss_np = np.array(test_l)\n","accuracy_np = np.array(accuracy)\n","np.save('gpt_big_loss', test_loss_np)\n","np.save('gpt_big_accuracy', accuracy_np)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-14T14:23:23.605978Z","iopub.status.busy":"2024-05-14T14:23:23.605619Z","iopub.status.idle":"2024-05-14T14:23:23.611323Z","shell.execute_reply":"2024-05-14T14:23:23.610437Z","shell.execute_reply.started":"2024-05-14T14:23:23.605950Z"},"trusted":true},"outputs":[],"source":["del model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(torch.cuda.memory_allocated(device))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), \"model.pt\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4991505,"sourceId":8391414,"sourceType":"datasetVersion"},{"datasetId":4997471,"sourceId":8399615,"sourceType":"datasetVersion"}],"dockerImageVersionId":30700,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
